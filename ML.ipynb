{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1).\n",
        "What is a parameter ?"
      ],
      "metadata": {
        "id": "fDtfEARWw8jN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANS1).\n",
        "   In machine learning, a parameter refers to an internal variable within a model that is learned from the training data. These parameters are adjusted during the training process to optimize the model's performance and ability to make accurate predictions."
      ],
      "metadata": {
        "id": "CbopsGN5xDX1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2).\n",
        "  What is correlation?\n",
        " What does negative correlation mean?"
      ],
      "metadata": {
        "id": "6AhlJ8OyxN5C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans2)\n",
        "\tCorrelation helps us understand the relationships between variables in our dataset, which is crucial for building effective ML models. For instance, understanding the relationship between features and the target variable can help us choose the right algorithm or feature engineering techniques.\n",
        "\n",
        "  Negative Correlation:\n",
        "When two variables have a negative correlation, an increase in one variable is associated with a decrease in the other. This is often represented by a downward-sloping line on a scatter plot\n"
      ],
      "metadata": {
        "id": "OqE0JnafxS68"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.\n",
        "  Define Machine Learning. What are the main components in Machine Learning?\n",
        "  "
      ],
      "metadata": {
        "id": "bOPrPWY6xyM5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans3)\n",
        "\tMachine learning (ML) is a subset of artificial intelligence (AI) that enables computers to learn from data without being explicitly programmed. The main components of ML include data, algorithms, models, and predictions."
      ],
      "metadata": {
        "id": "p5coWQBXx3h_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.\n",
        "  How does loss value help in determining whether the model is good or not?\n",
        "  "
      ],
      "metadata": {
        "id": "Iv8WUxYuzl2U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans4)\n",
        "\tIn Machine Learning, loss value is a key indicator of model performance, essentially measuring how wrong a model's predictions are. A lower loss value indicates that the model's predictions are closer to the actual values, suggesting a better-performing mode\n"
      ],
      "metadata": {
        "id": "brSl4TYszsUT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.\n",
        "   What are continuous and categorical variables?\n",
        "   "
      ],
      "metadata": {
        "id": "dIpAqwsZz9II"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans5)\n",
        "\n",
        "\tIn statistics, continuous variables represent numerical data that can take any value within a specific range, while categorical variables represent data that can be divided into distinct categories\n"
      ],
      "metadata": {
        "id": "30UbQWGP0CHB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.\n",
        "   How do we handle categorical variables in Machine Learning? What are the common techniques?"
      ],
      "metadata": {
        "id": "yivhodBK0Ei2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans6)\n",
        "\tHandling categorical variables in machine learning involves converting them into a numerical format that models can understand. Common techniques include one-hot encoding, label encoding, ordinal encoding, and target encoding. The best approach depends on the type of categorical data (nominal or ordinal) and the model being used.\n"
      ],
      "metadata": {
        "id": "Lx0EvBEb0KM4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.\n",
        "  What do you mean by training and testing a dataset"
      ],
      "metadata": {
        "id": "R8VRmdrK0M05"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans7)\n",
        "\tThe training set is used to teach the model how to perform a task by providing it with labeled examples. The testing set is a separate set of data used to evaluate the trained model's performance on unseen data, indicating how well it generalizes.\n"
      ],
      "metadata": {
        "id": "NMuYTczH0RNx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.What is sklearn.preprocessing?"
      ],
      "metadata": {
        "id": "2PBAhUOK0Tdk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans8)\n",
        "\tthe context of the scikit-learn library for Python, preprocessing refers to the process of transforming raw data into a format that is more suitable for machine learning algorithms.\n"
      ],
      "metadata": {
        "id": "BsETcORT0UiR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.\n",
        "   What is a Test set?"
      ],
      "metadata": {
        "id": "N6ynXbnH0ZvC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans9)\n",
        "\tTest Sets are logical groups of test cases. The purpose of test sets is to define groups of tests that should be executed together within one run. For instance, a smoke test is a group of tests that only check for top-critical capabilities. Whenever any test case from a smoke test fails, there is a critical problem\n"
      ],
      "metadata": {
        "id": "rXt_TVJB0dvb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.\n",
        "  How do we split data for model fitting (training and testing) in Python?\n",
        " How do you approach a Machine Learning problem?"
      ],
      "metadata": {
        "id": "g4CLjYGm0fDJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans10)\n",
        "\n",
        "an Python, you can split data for model training and testing using the train_test_split function from the scikit-learn library. This function divides your data into training and testing sets, with a common split being 80% for training and 20% for testing, or similar.\n",
        "\n",
        "\tstart by clearly defining the problem and setting clear goals, then determine the appropriate data collection and preprocessing steps. Next, select an appropriate model, train it, and rigorously evaluate its performance using validation techniques.\n"
      ],
      "metadata": {
        "id": "YdUT-OOn0g_h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.\n",
        "   Why do we have to perform EDA before fitting a model to the data"
      ],
      "metadata": {
        "id": "LiEXEcTU0kcX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans11)\n",
        "\tExploratory Data Analysis (EDA) is crucial before fitting a model because it helps ensure data quality, reveals patterns, and informs the model building process.\n"
      ],
      "metadata": {
        "id": "vGydW2si0mpa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12.\n",
        "   What is correlation?"
      ],
      "metadata": {
        "id": "1WI45Lb_0pea"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans12)\n",
        "\tThe statistical relationship between two or more variables, indicating how much they tend to change together\n"
      ],
      "metadata": {
        "id": "fN6oW7gu0q6p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13.\n",
        "  What does negative correlation mean?"
      ],
      "metadata": {
        "id": "StvOPrm80yaZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans13)\n",
        "\tA negative correlation means that two variables tend to move in opposite directions. When one variable increases, the other variable tends to decrease, and vice versa. This relationship is also known as an inverse correlation.\n"
      ],
      "metadata": {
        "id": "Qw6_Lo2e01iS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14.\n",
        "   How can you find correlation between variables in Python?"
      ],
      "metadata": {
        "id": "L5DsoSid04TJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans14)\n",
        "\tTo use the corrcoef() function, you need to pass in two arrays of data, one for each variable. The function will return a correlation matrix, which is a square matrix where the diagonal elements are always 1 and the off-diagonal elements indicate the correlations between different variables.\n"
      ],
      "metadata": {
        "id": "8NPDE-fQ05ty"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15.\n",
        "  What is causation? Explain difference between correlation and causation with an example."
      ],
      "metadata": {
        "id": "TbXqIjWM07rg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans15)\n",
        "\tCausation means one event directly causes another, while correlation indicates a relationship between two events without necessarily implying cause and effect\n",
        "ex:- The sun's rays directly cause a sunburn."
      ],
      "metadata": {
        "id": "8XmiggFB0-Q5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16.What is an Optimizer? What are different types of optimizers? Explain each with an example."
      ],
      "metadata": {
        "id": "eHgs4rzw1Bmv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans16)\n",
        "\tAn optimizer in machine learning is an algorithm used to adjust the parameters of a model (like weights and biases) during training to minimize the loss function.\n"
      ],
      "metadata": {
        "id": "-7d8zCac1Czk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17\n",
        "   What is sklearn.linear_model ?"
      ],
      "metadata": {
        "id": "UGaNGyBN1Eue"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans17)\n",
        "\tinear_model is a class of the sklearn module if contain different functions for performing machine learning with linear models. The term linear model implies that the model is specified as a linear combination of features.\n"
      ],
      "metadata": {
        "id": "r3KI5aZs1Jb7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. What does model.fit() do? What arguments must be given"
      ],
      "metadata": {
        "id": "_TSbniaF1L_A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans18)\n",
        "\tIn machine learning, model.fit() is a method that trains a model on a given dataset. It's a key part of the training process, where the model learns from the data by adjusting its internal parameters (like weights in a neural network) to minimize a loss function.\n",
        "\n",
        "\t1.\n",
        "\t\tx (input data): This is the data used to train the model (features).\n",
        "\n",
        "    Can be a NumPy array, pandas DataFrame, or a generator.\n",
        "\n",
        "    For supervised learning, it’s typically a 2D array (samples x features)"
      ],
      "metadata": {
        "id": "8BbCgm_e1NUE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19.\n",
        " What does model.predict() do? What arguments must be given"
      ],
      "metadata": {
        "id": "sb7rRwUj3Dga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans19)\n",
        "\tThe model.predict() method is used to make predictions from a trained model. After you have trained your model using model.fit(), you can use model.predict() to generate predictions on new, unseen data based on what the model has learned.\n",
        "  1.\n",
        "    verbose (optional):\n",
        "\n",
        "    Controls the verbosity of the prediction process. Usually not a big deal here, but if you pass 1, you'll see a progress bar during prediction."
      ],
      "metadata": {
        "id": "409sXqfK3FC9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20.\n",
        "   What are continuous and categorical variables"
      ],
      "metadata": {
        "id": "FqhDUAFa907j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans20)\n",
        "\tcontinuous variables represent numerical data that can take any value within a specific range, while categorical variables represent data that can be divided into distinct categories.\n"
      ],
      "metadata": {
        "id": "bGafzgdO923N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. What is feature scaling? How does it help in Machine Learning"
      ],
      "metadata": {
        "id": "c0sRtYx198ej"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans21)\n",
        "\tFeature scaling in machine learning is a data preprocessing technique that transforms the values of different features to a similar range.\n"
      ],
      "metadata": {
        "id": "NYP2aYih9-Zj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22.\n",
        " How do we perform scaling in Python"
      ],
      "metadata": {
        "id": "HiPbVKsg-AZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Create a MinMaxScaler object\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Fit the scaler to your data and transform it\n",
        "scaled_data = scaler.fit_transform(your_data)\n"
      ],
      "metadata": {
        "id": "t12u3C56-v4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "23.What is sklearn.preprocessing"
      ],
      "metadata": {
        "id": "48K2187JBPwf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans23)\n",
        "\tIn the context of the scikit-learn library for Python, preprocessing refers to the process of transforming raw data into a format that is more suitable for machine learning algorithms.\n"
      ],
      "metadata": {
        "id": "YLLB3qb_BRLw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "24.How do we split data for model fitting (training and testing) in Python?"
      ],
      "metadata": {
        "id": "2_rIAeruBT1o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans24)\n",
        "\tIn Python, you can split data for model training and testing using the train_test_split function from the scikit-learn library."
      ],
      "metadata": {
        "id": "2Bb0TUbMBVRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Sample data (replace with your actual data)\n",
        "data = {'feature1': [1, 2, 3, 4, 5],\n",
        "        'feature2': [6, 7, 8, 9, 10],\n",
        "        'target': [11, 12, 13, 14, 15]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "X = df[['feature1', 'feature2']]  # Features\n",
        "y = df['target']  # Target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Now you can train your model with X_train and y_train,\n",
        "# and evaluate it with X_test and y_test\n"
      ],
      "metadata": {
        "id": "yR-BEHzDBesQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "25.\n",
        "Explain data encoding?"
      ],
      "metadata": {
        "id": "tsX3ptHoBiQL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans25)\n",
        "\tData encoding is the process of converting information into a specific format, typically for storage, transmission, or processing, according to Lenovo. It's a fundamental concept in computing, enabling efficient handling of diverse data types, including text, images, and audio, as explained on edX.\n",
        ""
      ],
      "metadata": {
        "id": "Z5ZwQeK8Bju5"
      }
    }
  ]
}